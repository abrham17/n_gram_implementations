{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnftbSF8GJdCESxJEg3wJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrham17/n_gram_implementations/blob/main/n_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import re"
      ],
      "metadata": {
        "id": "yhU-TdgJeMUb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corpus_ngram(text_link, n):\n",
        "    try:\n",
        "        # Convert Google Drive view link to a direct download link\n",
        "        file_id = text_link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        \"https://drive.google.com/file/d/1WnuCIeZglWU0uty8-uMOBwOWQM-zAHBJ/view?usp=sharing\"\n",
        "        download_link = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "        output_file = \"corpus.txt\"\n",
        "        gdown.download(download_link, output_file, quiet=False)\n",
        "\n",
        "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        words = re.split(r'\\s+', text.strip())\n",
        "\n",
        "        def generate_ngrams(words, n):\n",
        "            for i in range(len(words) - n + 1):\n",
        "                yield tuple(words[i:i + n])\n",
        "\n",
        "        return generate_ngrams(words, n)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Exception: {e}\")\n",
        "\n",
        "threegrams = corpus_ngram(\"https://drive.google.com/file/d/1WnuCIeZglWU0uty8-uMOBwOWQM-zAHBJ/view?usp=sharing\", 3)\n",
        "for _ in range(10):\n",
        "    print(next(threegrams))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "093Ltqb8lpKm",
        "outputId": "4d11f264-634e-4656-a6fe-00e0d7db8e48"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1WnuCIeZglWU0uty8-uMOBwOWQM-zAHBJ\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1WnuCIeZglWU0uty8-uMOBwOWQM-zAHBJ&confirm=t&uuid=e3cac28a-bdda-4ee1-8820-dedef7d146c0\n",
            "To: /content/corpus.txt\n",
            "100%|██████████| 1.06G/1.06G [00:11<00:00, 89.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ምን', 'መሰላችሁ?', '(አንባቢያን)')\n",
            "('መሰላችሁ?', '(አንባቢያን)', 'ኢትዮጵያ')\n",
            "('(አንባቢያን)', 'ኢትዮጵያ', 'በተደጋጋሚ')\n",
            "('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው')\n",
            "('በተደጋጋሚ', 'ጥሪው', 'ደርሷት')\n",
            "('ጥሪው', 'ደርሷት', 'ልትታደመው')\n",
            "('ደርሷት', 'ልትታደመው', 'ያልቻለችው')\n",
            "('ልትታደመው', 'ያልቻለችው', 'የአለም')\n",
            "('ያልቻለችው', 'የአለም', 'የእግር')\n",
            "('የአለም', 'የእግር', 'ኳስ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probability(ngrams):\n",
        "  count_ngram = {}\n",
        "  for words in ngrams:\n",
        "    if words in count_ngram:\n",
        "      count_ngram[words] += 1\n",
        "    else:\n",
        "      count_ngram[words] = 1\n",
        "  probability_count = {}\n",
        "  for words in count_ngram:\n",
        "    probability_count[words] = count_ngram[words] / len(ngrams)\n",
        "  top_10_ngrams = dict(sorted(probability_count.items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "  return top_10_ngrams\n",
        "calculate_probability(threegrams)"
      ],
      "metadata": {
        "id": "A-BrpFe4P_Tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}